<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Recording - Lecture Transcription</title>
    <link rel="icon" href="/static/favicon.png">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .back-link {
            display: inline-block;
            margin: 20px;
            color: white;
            text-decoration: none;
            font-size: 16px;
            font-weight: 500;
        }

        .back-link:hover {
            text-decoration: underline;
        }

        .page-title {
            text-align: center;
            color: white;
            margin-bottom: 30px;
        }

        .page-title h1 {
            font-size: 36px;
            margin-bottom: 10px;
        }

        .page-title p {
            font-size: 16px;
            opacity: 0.9;
        }

        .container {
            display: grid;
            grid-template-columns: 1fr 2fr;
            gap: 30px;
            max-width: 1400px;
            margin: 0 auto;
            height: calc(100vh - 200px);
        }

        /* Left Side - Controls */
        .controls {
            background: white;
            border-radius: 15px;
            padding: 40px;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }

        /* Microphone Bubble */
        .mic-bubble {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 60px;
            margin-bottom: 30px;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }

        .mic-bubble.recording {
            background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
        0%, 100% {
            transform: scale(1);
            box-shadow: 0 8px 25px rgba(239, 68, 68, 0.4);
                }
        50% {
            transform: scale(1.08);
            box-shadow: 0 12px 35px rgba(239, 68, 68, 0.6);
            }
        }

        .mic-bubble:hover {
            transform: scale(1.05);
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.5);
        }

        /* Status */
        .status {
            text-align: center;
            padding: 0;
            margin-bottom: 30px;
            font-weight: 500;
            min-width: 200px;
            font-size: 16px;
            color: #666;
        }

        .status.recording {
            color: #ef4444;
        }


        /* Instructions */
        .instructions {
            margin-top: 30px;
            text-align: center;
            color: #666;
            line-height: 1.6;
        }

        .instructions p {
            margin: 10px 0;
        }


        /* Right Side - Transcript */
        .transcript-area {
            background: white;
            border-radius: 15px;
            padding: 30px;
            overflow-y: auto;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }

        .transcript-area h2 {
            color: #333;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #e5e7eb;
        }

        .empty-state {
            text-align: center;
            color: #999;
            padding: 60px 20px;
            font-size: 16px;
        }

        .empty-state-icon {
            font-size: 60px;
            margin-bottom: 20px;
            opacity: 0.5;
        }

    .transcript-chunk {
        background: #f9fafb;
        border-left: 4px solid #667eea;
        border-radius: 8px;
        padding: 15px;
        margin-bottom: 15px;
        transition: all 0.2s ease;
    }

    .transcript-chunk:hover {
        background: #f3f4f6;
        transform: translateX(5px);
    }

    .timestamp {
        font-size: 12px;
        color: #9ca3af;
        margin-bottom: 8px;
        font-weight: 500;
    }

    .transcript-text {
        font-size: 16px;
        color: #1f2937;
        line-height: 1.6;
    }

    /* Responsive */
    @media (max-width: 1024px) {
        .container {
            grid-template-columns: 1fr;
            height: auto;
        }

        .controls {
            margin-bottom: 20px;
        }

        .transcript-area {
            min-height: 400px;
        }
    }


    </style>
</head>
<body>
    <a href="/" class="back-link">‚Üê Back to Home</a>

    <div class="page-title">
        <h1>üéôÔ∏è Live Recording</h1>
        <p>Record and transcribe in real-time</p>
    </div>

    <div class="container">
        <!-- Left: Controls -->
        <div class="controls">
            <div class="mic-bubble" id="micBubble">üé§</div>

            <div id="status" class="status idle">
               Click the microphone to start recording
            </div>


            <div class="instructions">
                <p><strong>How to use:</strong></p>
                <p>1. Click "Start Recording"</p>
                <p>2. Allow microphone access</p>
                <p>3. Speak naturally</p>
                <p>4. Transcription appears automatically</p>
                <p>5. Click "Stop" when done</p>
            </div>
        </div>

        <!-- Right: Transcript -->
        <div class="transcript-area" id="transcriptArea">
            <h2>Transcription</h2>
            <div id="transcriptContent">
                <div class="empty-state" id="emptyState">
                <div class="empty-state-icon">üìù</div>
                <p>Start recording to see transcription appear here...</p>
            </div>
        </div>

    </div>

    <script>
    // ===== 1. TRACK STATE =====
    let isRecording = false;
    let websocket = null;
    let audioContext = null;

    // ===== 2. GET ELEMENTS =====
    const micBubble = document.getElementById('micBubble');
    const statusDiv = document.getElementById('status');
    const transcriptArea = document.getElementById('transcriptArea');
    const transcriptContent = document.getElementById('transcriptContent');
    const emptyState = document.getElementById('emptyState');


    // ===== 3. CLICK HANDLERS =====

    // CLICK MICROPHONE
    micBubble.addEventListener('click', () => {
        if (!isRecording) {
            startRecording();
        } else {
            stopRecording();
        }
    });


    // START RECORDING

    async function startRecording() {
        //CHANGE CSS STYLE
        isRecording = true;
        statusDiv.textContent = 'Recording... (Click to stop)';
        statusDiv.className = 'status recording';

        //IMPLEMENT JS LOGIC
        try{
            // 1. Get microphone access via browser Web API
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: { sampleRate : 16000,
                         channelCount : 1
                        }
            });

            // Establish Web-socket connection with backend
            websocket = new WebSocket('ws://localhost:8000/ws/transcribe');

            // states of websocket connection with corresponding function to be implemented in each state

            //Connection opened
            websocket.onopen = () => {
                micBubble.classList.add('recording');
                statusDiv.textContent = 'Recording... (Click to stop)';
                statusDiv.className = 'status recording';
            }

            // Server sends transcription
            websocket.onmessage = (event) =>{
                const data = JSON.parse(event.data)
                if (data.type === 'transcription'){
                    //Display it
                    addTranscription(data.text)
                }
            }

            //Error --connection failed
            websocket.onerror = (error) => {
                stopRecording();
                alert('Cannot connect to server. Is it running on port 8000?');
            }

            // Connection closed or intentionally dropped
            websocket.onclose = (event) => {
                stopRecording();
                // Check if it was unexpected, if done intentionally , dont show alert, bad UX
                if (isRecording) {
                    statusDiv.textContent = 'Connection lost!';
                    statusDiv.style.color = '#f59e0b'; // Orange
                }

                //Try to reconnect
                const shouldReconnect = confirm('Connection lost! Try reconnecting?');
                if (shouldReconnect) {
                    stopRecording();                           // 1. Clean up old connection
                    setTimeout(() => startRecording(), 1000);  // 2. Wait 1 sec, then try again
                }
            }

            // 4. Setup Audio Processing
            audioContext = new AudioContext({ sampleRate : 16000});
            const source = audioContext.createMediaStreamSource(stream);
            const processor = audioContext.createScriptProcessor(4096,1, 1);
            source.connect(processor);
            processor.connect(audioContext.destination);

            //5. Send Audio to Server
             processor.onaudioprocess = (e) => {
                if (websocket && websocket.readyState === WebSocket.OPEN){
                    const audioData = e.inputBuffer.getChannelData(0);


                    //Convert to INT16 matched for Server format
                    const int16 = new Int16Array(audioData.length);
                    for( let i =0; i<audioData.length; i++){
                        int16[i] = audioData[i] * 32767;
                    }

                    //Send to server
                    websocket.send(int16.buffer)
                }
            };

        }
        catch(error){
            alert('Error: ' + error.message);
            statusDiv.textContent = 'Click to start';
            statusDiv.className = 'status idle';
            isRecording = false; // Reset flag
        }

    }

    function stopRecording() {
        if (audioContext) audioContext.close();
        if (websocket) websocket.close();
         //CHANGE CSS STYLE
        isRecording = false;
        micBubble.classList.remove('recording');
        statusDiv.textContent = 'Click to start recording';
        statusDiv.className = 'status idle';
    }


    // Display Transcription
    function addTranscription(text){
        emptyState.style.display = 'none';
        const div = document.createElement('div');
        div.className = 'transcript-chunk';
        div.innerHTML = `
            <div class= "timestamp">${ new Date().toLocaleTimeString()}</div>
            <div class = "transcript-text">${text}</div>
        `;
        transcriptContent.appendChild(div);
        transcriptArea.scrollTop = transcriptArea.scrollHeight;

    }

    </script>
</body>
</html>